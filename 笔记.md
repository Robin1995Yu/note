## java 基础
### 参数传递问题
java 参数传递为值传递。
- 基本类型参数。传递后栈指针指向内存中的【新分配】的变量值。= 操作后只改变新分配的变量值，不改变原值
- 对象类型参数。传递后栈指针指向原引用指向的堆内对象实例。= 操作后只改变栈指针指向的对象实例，不会改变原值（原引用）。对对象的 set/其他操作因为指向同一个对象，将改变对象的属性

### String
不可变类，每次 +操作生成新的对象

### HashMap
- 容量值为什么要是2的指数次
    - 扩容时左移，比乘法效率高。put 时定位下标使用 (n-1)&hash，比取模效率高

### 动态代理实现方式
#### jdk
基于接口生成对应的 class 文件，所有接口方法实现调用 InvocationHandler。代理类创建性能高，调用性能较低

#### cglib
基于继承生成对应的 class 文件。

#### javassist
直接操作字节码，可以比较自由的用 java 编码编写代理类，手工生成的字节码小。dubbo 默认实现。

## java 并发
### 线程池
当线程池中线程数量少于 *coreSize* 时，来一个任务创建一个线程，由 *threadFactory* 创建线程

大于 *coreSize* 但小于 *maxSize* 时，将任务扔到 *BlockingQueue*（一般是有界阻塞队列） 中

当 *BlockingQueue* 满了的时候，会创建线程，但数目不会超过 *maxSize*。但当线程在 *keepAlive* 时间内未获取到任务（空闲时间超过 keepAlive）时，线程会结束(如果设置了 allowCoreThreadTimeOut = true，核心线程也会执行这个逻辑)

当大于 *maxSize* 时，会执行 *rejectHandler* 拒绝策略。默认抛 RejectedExecutionException

- 线程池中维护了内部类 Work 的 Set，Work 中持有 Thread
- 创建出来的线程一直自旋(Work 中 taskTask 方法)，不断从 queue 中 take 任务，执行任务
- 当线程数大于 coreSize 时，调用带超时时间（keepAliveTime）的 poll 从 queue 获取任务，一旦超时线程就结束。来实现大于 coreSize 线程 keepAliveTime 空闲后结束
- 线程池响应 Future，submit 方法中将参数的 callable 包装成了 FutureTask（它实现了 runnable 及 Future，它的 run 方法会保存 call 的响应值）,相当于做了适配，后续调用 execute 方法执行还是当做 runnable 执行了，用了模板方法

#### 生命周期
1. running。可接受新任务且正在执行队列中任务
2. shutdow。优雅退出，不接受新任务，但会执行队列中任务
3. shutdownNow。暴力退出，不接受新任务，且不执行队列中任务，还中断正在执行的任务
4. tidying。没任务了，准备退出了。
5. terminated。已经结束了

### 锁
#### volatile 
- 实现可见性、顺序性
- 读操作前添加 load 读屏障，强制把主内存刷新到工作内存读取变量。在写操作前添加 store 写屏障，强制把工作内存刷到主内存。屏障保证不会重排序
#### synchronized
https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247488083&idx=2&sn=41c8fdd7b333e80f6fdc4ac80c28caf9&chksm=fa496de2cd3ee4f411e1c0608f62d3a31c7b6d5ff0332bf90d5033df961809ea6961d7226361&scene=27#wechat_redirect
- jvm 同步方法使用 ACC_SYNCHRONIZED 标记。同步代码块使用 monitorenter、monitorexit。都基于 Monitor 实现
- 每个对象会关联一个 Monitor,Monitor 中有三个空间
    - Special Room。仅容纳一个线程，即持有该锁的线程
    - Entry Set。等待该锁阻塞的所有线程
    - Wait Set。调用 wait 后等待的所有线程 
- jdk 1.6 后进行了锁优化
    - 偏向锁。同一个线程多次申请同一个锁竞争
    - 轻量级锁。线程交替执行同步块的场景，绝大部分的锁在整个同步周期内都不存在长时间的竞争。支持自旋，不会放弃 cpu 时钟。因为线程的阻塞、唤醒需要操作系统参与，用户态内核态切换耗时
    - 重量级锁。进入 Monitor
    - 锁消除。动态编译时 JIT 编译器若发现某个锁永远不会有多线程竞争，消除锁
    - 锁粗化。一段代码中连续对同个对象反复加锁解锁，同一个人，要办理多个业务的时候，可以在同一个窗口一次性办完，而不是多次取号多次办理

### AQS
AQS 中封装了像 cas、阻塞、唤醒线程的 native 方法。其中维护了 state 状态结合 cas 可以很方便实现独占/共享锁。其中 aquire、release 方法操作了带 Thread 线程数据的链表，实现了将未获取到同步状态的线程阻塞，释放同步状态后从链表中获取线程并唤醒的操作
https://mp.weixin.qq.com/s/3eUiYIxCU4XVw3p3wy4bKA
https://mp.weixin.qq.com/s/45NSVacLvuCcM7eOUSm8KQ
- state 状态。volatile 修饰的 int 值，暴露了仅供子类操作的 get、set、cas 方法。若子类想实现独占锁，即控制 state 0/1，实现信号量，即 acquire state -1，release state +1.
- 调用 acquire 方法时，会调用子类实现的 tryAcquire，失败时将当前线程包装成内部类 Node，放入 AQS 维护的 Node 双向链表里，并调用 native 方法将线程阻塞
- 调用 release 方法时，会调用子类实现的 tryRelease，释放后从 Node 链表中选择线程调用 native 方法唤醒
- ReentrantLock、Semaphore 都是组合了一个 AQS 的实现 Sync，通过操作 Sync 实现对应的同步操作
- BlockingQueue 持有 ReentrantLock 及其产生的两个 Condition（AQS 中内部类 ConditionObject 实现该接口）（空、满）,当空/满时将需要阻塞的线程加入到 ConditionObject（内部类持有外部类 AQS 对象） 中的线程队列中，当 condition.signalAll() 的时候，将线程加入到 AQS 的 Nodee 链表里

### 并发工具/容器
- ConcurrentHashMap。线程安全版本的 HashMap。get 方法一直不加锁。1.7 及前结构类似于 HashMap 数组（链表数组的数组）使用分段锁优化。1.8 后结构同 HashMap（链表/红黑树数组）,加了红黑树优化，当对应 hashcode 的槽（Node）为空时使用 cas 设置 node，不为空时使用 synchronized 加锁
- CountDownLatch。当前线程 await 阻塞直到其他多个线程将 latch countdown 到0，就像在当前线程 join 了多个线程，需要等其他多个线程运行结束后当前线程才能继续执行
- CyclicBarrier。多个线程中都会调用 await，阻塞直到所有线程都执行到 await 才一起开始继续执行
- Semaphore。信号量，仅允许 acquire n 次，大于 n 次的线程将等待直到已 acquire 的线程 release


### ThreadLocal
线程独立副本，没有线程安全问题。Thread 对象里 ThreadLocalMap 的模板类，实际将数据存在 ThreadLocalMap<ThreadLocal,T> 中
- 使用场景
    - 多方法共享变量（xxContext）
- 注意事项
    - ThreadLocalMap 中 key 是对 ThreadLocal 的弱引用，value 是强引用。如果在线程栈中把 ThreadLocal 设为 null/业务方法执行完局部变量正常出栈（去掉了栈对堆里 ThreadLocal 的强引用，只剩下了 ThreadLocalMap 对 ThreadLocal 的弱引用），gc 的时候会把 key 的 ThreadLocal 清除，而对应的 value 实例已经无法从 ThreadLocalMap 中映射，造成内存泄露。ThreadLocal  get set 时会对 ThreadLocalMap 中 key 为 null（被 gc 清除的 ThreadLocal）entry 做清理。所以从线程栈中把 ThreadLocal 设为 null 到调用 ThreadLocal get/set 或者线程消亡（栈对 ThreadLocalMap 的强引用也断掉，ThreadLocalMap 可回收）这段时间一直有内存泄露危险。使用线程池的时候需要特别注意，因为线程池中的线程一直不会消亡，要特别注意对 threadLocal 的清理（执行完业务逻辑调用 remove）

### 典型案例
- 生产者、消费者
```java
synchronized 版:
消费者
synchronized (对象) {
    处理逻辑（可选）
    while(条件不满足) {
        对象.wait();
    }
    处理逻辑（可选）
}

生产者
synchronized (对象) {
    完成条件
    对象.notifyAll();、
}

ReentrantLock 版:
消费者
lock.lock();    //获取锁
try {
    while (条件不满足) {
        condition.await();  //使线程处于等待状态
    }
    条件满足后执行的代码;
} finally {
    lock.unlock();    //释放锁
}

生产者
lock.lock();    //获取锁
try {
    完成条件;
    condition.signalAll();  //唤醒处于等待状态的线程
} finally {
    lock.unlock();    //释放锁
}

BlockingQueue 版
消费者、生产者持有同个 queue，消费者一直 take，生产者一直 offer



```

## java 命令
### 内存使用情况
排查内存泄露问题
- jps 查看 java 程序进程 pid
- jstat -gc 查看 gc 情况
- jmap 查看内存使用情况
    - jmap -histo <pid> 查看各个对象个数及占用内存
    - jmap -heap <pid> 查看堆相关参数及新生代老年代各区内存使用情况
    - jmap -dump:format=b,file={fileName} <pid> 生成 dump 文件。结合 jhat 命令将 dump 文件转换为 html 在浏览器查看，jhat 提供类似 sql 的 oql 查询语句。或者用其他 dump 文件分析工具分析

### 线程运行情况
死锁、死循环、线程长时间等待分析
- jps 查看 java 程序进程 pid
- jstack 查看线程运行情况及持有锁、等待锁情况

## 线上问题排查
### oom
#### 原因
- 内存分配的确实太小，业务确实需要很多内存
- 某对象频繁申请，但未正常释放，导致内存泄漏
- 某资源（线程/网络连接/文件描述符）频繁申请，资源耗尽
#### 排查步骤
- jmap -heap 查看堆内存使用情况
- jmap -histo 查看最耗内存对象
    - 判断对象情况是否正常，正常就加内存分配，不正常结合代码排查
- pstree 或者 /proc/${PID}/task 查看进程线程数
- netstat 或者 /proc/${PID}/fd 查看文件句柄/连接数

### cpu 100%
#### 原因
- 线程太多，上下文频繁切换
- 应用代码死循环无线递归
- 死锁
- 频繁 full gc
#### 排查步骤
- top -c 找到最耗 cpu 的进程
- top -Hp {pid} 找到最耗 cpu 的线程
- jstack 查看对应线程的堆栈信息、锁情况
- 根据堆栈找到对应的代码
    
## jvm
### 内存结构
对象实例存在堆里，对象引用存在栈里，对象元数据存在方法区
- 堆【线程共享】（运行时各类对象实例）
- 方法区【线程共享】(存放 class 信息、常量、静态变量等。1.8 后改为直接内存中元空间)
    - 原方法区根据参数固定大小，可能 oom，无法动态调整。元空间默认可以动态调整，理论上只受机器本身内存限制
- 线程空间【线程独立】
    - 程序计数器。这个线程执行到哪行代码了
    - 虚拟机栈。线程局部变量
    - 本地方法栈。本地方法信息


### 垃圾回收
#### 存活判断
- 引用计数(无法解决循环引用)
- 可达性分析。是否可从 GC Root 搜索到，Gc Root 包括
    - 虚拟机栈引用对象（生存的线程局部变量）
    - 方法区静态变量/常量引用对象
    - 本地方法栈引用对象
        - 强引用。不会被垃圾回收
        - 软引用。内存不够了才回收
        - 弱引用。垃圾收集碰到就回收
        - 虚引用。基本等于没引用

#### 回收算法
- 标记-清除。先标记，后清除，存在内存碎片
- 复制算法。将内存空间分为两块，A块用完将存货对象复制到B块，清理A块所有内存。实际并非1:1，hotSpot 默认新生代使用复制算法 1:1:8，Eden 区 8，两个 survivor 区 1
- 标记-整理算法。标记后将存活对象移动
- 分代收集算法，将内存空间分成几块，不同块使用上述不同算法。

#### 收集器
算法是方法论，收集器是实现
- Serial 收集器。串行收集，stop the world，新生代复制，老年代标记-压缩
- ParNew 收集器。serial 多线程版本，stop the world，新生代多线程复制，老年代单线程标记-压缩
- Parallel Scavenge 收集器。类似 ParNew，单更注重吞吐量，提高 CPU 利用率
- CMS 收集器。基于标记-清除算法，目标是最短停顿时间，缺点会产生大量碎片，并发阶段会降低吞吐量
    1. 初始标记。stop the world，仅标记 GC Root 能【直接关联】到的对象
    2. 并发标记。标记需要被清理的对象，时间最长
    3. 重新标记。stop the world，修正并发标记时因为用户线程导致的被清理对象变化
    4. 并发清除。
- G1 收集器。CMS 的优化版本，实现空间整理，避免过多碎片。实现可预测停顿，将所有内存划分为大小相等的 region，跟踪每个 region 的价值大小，维护优先队列，结合停顿时间制定回收计划
    1. 初始标记。stop the world，仅标记 GC Root 能【直接关联】到的对象
    2. 并发标记。标记需要被清理的对象，时间最长，发现 region 都是垃圾直接清理
    3. 最终标记。stop the world，修正并发标记变化
    4. 筛选回收。根据 region 回收价值优先队列结合用户期望停顿时间，执行回收及整理

#### 分配策略
- 对象优先在新生代 eden 区分配，eden 区不够了 minor gc 下再试下
- 大对象直接进入老年代
- 长期存活对象进入老年代。根据对象头中对象年龄判断，年龄可配置
- 动态对象年龄判断。不一定等新生代对象到达配置年龄，若大于等于某年龄的对象占比超过配置，直接将该年龄段对象放入老年代
- 空间分配担保。老年代最大可用连续空间小于新生代所有对象空间时，判断是否需要担保，连续空间大于平均新生代晋升空间，冒险尝试 minorGc。是否担保可配置

#### GC 优化原则
- 将进入老年代的对象数量降到最低
- 降低Full GC的时间
##### 比较重要 jvm 参数
- 启动 JVM 时堆内存大小。-Xms
- 堆内存最大限制。—Xmx
- 新生代、老年代内存比。-XX:NewRatio
- 新生代内存大小。-XX:NewSize
- 新生代中Eden区和Survivor区的内存比，默认 eden 区80%

### 类加载机制
将 class 文件中二进制数据加载到内存，对数据进行校验、转换解析合初始化，最终可以被虚拟机直接使用的 Java 类型
#### 类加载过程
1. 加载(把 class 文件放到内存里)
    - 根据类名获取对应二进制字节流
    - 将字节流对应存储结构存入方法区
    - 生成该类的 Class 对象，作为方法区访问入口
2. 连接
    - 验证。确保加载类正确性。文件格式、元数据、字节码、符号引用验证
    - 准备。为类静态变量分配内存并初始化为【默认值】。static 变量初始化默认值为 0，static final 初始化常量值
    - 解析。将类中的符号引用转换为直接引用。转换为可寻址的引用
3. 初始化(执行 Java 类初始化,静态变量、代码块初始化)
    - 先初始化父类
    - 初始化时机
        - new
        - 访问静态变量/方法
        - 反射
        - 初始化子类

#### 类加载器
双亲委派模型。先让父加载器尝试加载，不然一个类会被多个加载器加载

#### 双亲委派模型的破坏
- java spi 机制，比如 jdbc Driver 加载,Driver 接口及执行驱动设置的 Driver Manager 定义在 rt.jar 包里，由 Bootstrap ClassLoader 加载。各个厂商实现的 Driver 在 classpath 里，需要由 Application ClassLoader 加载。实际 Driver Manager 设置驱动的时候调用 Thread.currentThread().getContextClassLoader() 获取线程上下文类加载器（Application ClassLoader） 加载
- tomcat 单个 web 容器可能会部署多应用，多应用可能依赖了同个 jar 包的不同版本，需要保证每个应用的类库相互独立相互隔离

### 对象创建过程
1. 类加载检查。检查是否已被加载，类加载流程见下类加载过程。
2. 分配内存。如果内存规整，使用“指针碰撞”，挪动分界点指针。若不规整，“空闲列表”，需要记录哪些内存块可用。是否规整由垃圾回收算法是否带压缩整理决定
3. 初始化零值。变量默认值
4. 设置对象头。如对象哈希码、分带年龄、锁指针等

## mysql
### mysql 存储模型
#### 页
以页为单位存储，页中包含多条行记录。内存与磁盘交互的基本单位
https://mp.weixin.qq.com/s?__biz=MzIxNTQ3NDMzMw==&mid=2247483678&idx=1&sn=913780d42e7a81fd3f9b747da4fba8ec&chksm=979688eca0e101fa0913c3d2e6107dfa3a6c151a075c8d68ab3f44c7c364d9510f9e1179d94d&scene=21#wechat_redirect

- 页中数据按照主键排序，多个页之间也按照主键
- 页中将记录按照顺序多个记录归为一个槽，在页中查找对应数据时（按主键查找）先根据二分法找到对应的槽，在再槽中遍历找对应的记录
- 页头部信息保存页中包含多少条记录、页中有几个槽
- 页中行记录使用单链表，默认在所有数据行前，插入两条行，最大、最小记录
- file header 保存上一页、下一页指针

#### 行    
每一条记录
https://mp.weixin.qq.com/s?__biz=MzIxNTQ3NDMzMw==&mid=2247483670&idx=1&sn=751d84d0ce50d64934d636014abe2023&chksm=979688e4a0e101f2a51d1f06ec75e25c56f8936321ae43badc2fe9fc1257b4dc1c24223699de&scene=21#wechat_redirect
- 每一条记录（行）主要包含两部分内容
    - 记录真实数据，除了每列的值外还存隐藏列，row_id: 行ID，唯一标识一条记录，没有主键时存在。transaction_id： 事物 id。roll_pointer： 回滚指针
    - 额外信息
        - 变长列真实长度（如 varchar 列真实长度）
        - null 值列表
        - 其他头信息：在页中的位置、删除标识、下一行指针
        
### 索引
- 按照索引结构，B+ 树索引及 hash 索引
- 聚簇索引：叶子节点存放记录数据；非聚簇索引：叶子节点存放主键，先找到主键再用主键索引找数据；
- 索引最左比配原则，联合索引时按左列使用索引
- 覆盖索引，如果查询的列都包含索引就是覆盖索引，查询效率更高
#### 建立好的索引
- 索引有足够的区分度
- 索引顺序同查询顺序（符合最左匹配原则）
- 覆盖索引

### 事务
https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB(%E5%9B%BE%E6%96%87%E8%AF%A6%E8%A7%A3).md
- 事务特性，acid，原子性、一致性、隔离性、持久性
    - 原子性通过 undo log 实现。事务中每次操作生成对应的逆操作的 undo log，并把回滚指针指向对应的 undo log，事务失败时根据回滚指针找到 undo log 进行回滚
    - 持久性通过 redo log 实现。mysql 存储机制包含缓冲区，数据操作先走缓存，线程异步将缓存同步到磁盘。未同步时宕机会导致数据丢失。使用 redo log 机制，每次操作生成对应的 redo log，操作后直接将 redo log 落磁盘，宕机情况使用 redo log 恢复数据。
        - 为什么不直接把数据落磁盘而 redo log 落磁盘？redo log 顺序读写且相较于数据基本单位“页”来说数据较少，落磁盘更快
    - 隔离性用读写锁或 mvcc 机制实现
    - 一致性通过保证以上三个性质来实现
- 事务隔离级别
    - READ-UNCOMMITTED(读取未提交) ，可以读到其他事务未提交的更新值
    - READ-COMMITTED(读取已提交)，只能读到其他事务已经提交的更新值
    - REPEATABLE-READ(可重复读)，保证同一个事务对相同记录的查询结构一致，即使其他事物对该记录提交过修改
        - 默认隔离级别。基于行级锁实现隔离会出现幻读，事务A先查某 id 的记录不存在，其他事务插入新记录后，事务A插入记录会报冲突。通过在查询的时候添加 for update 加 next-key 锁（记录锁加 gap 锁。索引等值查询给相邻的 gap 加锁，范围查询给对应的范围加 gap 锁。非聚簇索引查询，在非聚簇索引上加 next-key 锁，在聚簇索引对应的记录上加 x 锁）解决
    - SERIALIZABLE(可串行化)，所有事务串行化
    
#### 锁
- 行级锁，锁的是索引
    - 锁 where 及 set 语句或查询时内容涉及的聚簇/非聚簇索引，delete 都锁。先锁 where 的索引再锁 set
- 意向锁。事务A在更新某记录时先加表的意向锁，再加对应记录的锁。事务B需要申请表锁的时候直接检查意向锁，不用遍历所有记录检查是否有锁

#### MVCC 多版本并发控制
相当于行级锁的一个变种，通过保存数据在某个时间点（事务）的快照,来实现读-写冲突的无锁并发控制（写写冲突还是需要锁）。只在读已提交、可重复读隔离级别下工作。https://blog.csdn.net/SnailMann/article/details/94724197
- 版本链。每行记录都有 tx_id 和 rollback 指针
  - tx_id 表示记录修改的事务 id
  - rollback 指针指向 undo log，记录上一次更新结果，组成了版本链，可以实现快照读
- Read View。事务进行快照读的时候生成 Read View，记录了数据库系统当时的所有活跃的事务列表。越新的事务 id 越大，可以实现版本控制的快照读
  - 读已提交。每次读的时候都重新生成 Read View
  - 可重复读。事务开始后第一个读的时候生成 Read View

### 优化
#### sql 执行慢的原因
- 查询没有建对应的索引
- 查询语句问题有索引但是没走索引。没符合最左匹配、字段上用了函数...
- 查询涉及非聚簇索引时，mysql 通过采样判断走非聚簇索引还不如扫全表。mysql 自身采样判断出错，查询时强制使用索引
- 偶现，mysql 本身在刷盘，在 redo log 刷盘是 sql 执行受影响
- 偶现，有锁等待

## 分布式事务
### 2pc 二阶段提交
依赖各个服务本地资源管理器，分布式事务中各个服务锁定对应资源。对业务逻辑无侵入，但存在协调者单点问题及锁定资源过长问题 https://www.infoq.cn/article/g1avP9FUA6CDOYRAlv4R
1. 准备阶段
    - 协调者向各服务发送 prepare 指令，各个服务执行业务逻辑但本地资源管理器不 commit，回 ack
    - 都 ack 进行提交，没有进行回滚
2. 提交/回滚阶段
    - 提交。各个服务资源管理器执行 commit
    - 回滚。各个服务资源管理器执行 rollback

### 3pc 三阶段提交
二阶段提交的改进，引入超时机制，避免了二阶段提交协调者 commit 阶段命令未送达长时间锁定资源的问题，但也会因超时机制小概率造成数据不一致
1. CanCommit。协调者询问各服务是否可以参与事务操作，并不执行事务
2. PreCommit。协调者让各个服务执行业务逻辑，不 commit
3. DoCommit。协调者让各个服务 commit/rollback 事务，如果 DoCommit 命令超时，服务自行 commit

### tcc
不依赖各服务本地资源管理，通过把业务逻辑拆解成 准备-提交/回滚 实现（类似预扣款等临时性操作）。定制化成本高，相当于侵入业务逻辑
https://www.cnblogs.com/jajian/p/10014145.html#autoid-3-4-0
https://www.bytesoft.org/
1. try 
    - 主服务调用各从服务执行临时性逻辑，tcc 框架通过接管本地事务管理器（如 Spring 的 TransactionManager）获取各个服务临时性逻辑 commit/rollback 情况
    - 从服务都 commit 执行 confirm，否则 cancel
2. confirm/cancel
    - confirm。各服务执行 confirm 逻辑，执行业务提交（例：预扣款变真实扣款）
    - cancel。各服务结合本地事务管理器 try 阶段 commit/rollback 情况，执行 cancel 逻辑或者不执行 cancel 逻辑

### 可靠消息
通过可靠的异步消息达成最终一致性，重点在于 producer 服务发消息跟 consumer 服务收消息的可靠性。在中间引入可靠消息服务组件确保收发消息可靠
https://www.cnblogs.com/jajian/p/10014145.html#autoid-3-4-0
1. producer 发送 “待确认” 消息给可靠消息服务组件，可靠消息服务组件开启 “待确认” 消息确认线程，若后续确认/删除超时就回调 producer 确认状态
2. producer 执行业务逻辑，成功发送确认消息，失败发送删除消息给可靠消息服务组件
3. 可靠消息服务组件收到成功消息，将该消息状态改为已发送并把消息发给 mq，开启 “已发送” 消息确认线程，若后续 ack 超时就把消息重新发给 mq
4. consumer 消费到消息，执行业务逻辑，发 ack 给可靠性消息服务组件
5. 可靠性消息服务组件把消息改为 “已完成”

## io
### linux io 模型
- 阻塞IO、非阻塞IO模型、信号驱动IO模型、IO复用模型、异步IO模型  https://segmentfault.com/a/1190000003063859
- Java NIO浅析 https://zhuanlan.zhihu.com/p/23488863
- 零拷贝。从文件读取内容传输到另一个服务器经历 4 次拷贝。1.磁盘 --> 内核态(DMA) 2.内核态 --> 用户态(CPU) 3.用户态 --> 内核态(CPU) 4.内核态 --> 网卡(DMA)。http://www.ijiandao.com/2b/baijia/316292.html

## 网络
### tcp
- 流量控制。接收方将自己可接受的大小发给发送方，避免发送方发送太多数据无法处理。可能接受到的数据一直没被应用层读取，占用缓存空间使窗口一直缩小，到 0 的时候，发送方会开启定时器，不断探测接收方窗口大小(窗口大小在 ack 包的头部)
- 半开连接。客户端宕机意外断开连接，tcp 默认两小时探活，会浪费服务端文件描述符资源。可以在应用层额外做符合业务的场景的探活机制。

### http
- http 1.1 默认开启 keep-alive，一个 tcp 连接可传多个 http 请求（串行）。用 Pipelining 可支持一个 tcp 连接多请求并行发送，但响应还是顺序的，但浏览器默认关闭。多路复用需要使用多个 tcp 连接，一般浏览器/手机对单个域名 server 连接数有限制
- http 2.0  https://www.jianshu.com/p/712eb3a65d33
  - 通过分帧（一个请求分成多个帧）实现了多路复用，同一个 tcp 连接可并行执行多 http 请求
  - header 头压缩，客户端、服务器维护了 header 索引表，传输时不传 header 值，传索引值


## 常用框架/存储
### spring
- spring bean 生命周期。根据配置文件加载注册 beanDefinition --> 初始化 bean --> 依赖注入 --> 处理 aware --> bpp 前置处理 --> 调用 afterPropertiesSet、init 方法 --> bpp 后置处理 --> 使用 bean --> 销毁 bean --> 调用 destroy 方法 https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/framework/spring/SpringInterviewQuestions.md#55-spring-%E4%B8%AD%E7%9A%84-bean-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F
- spring mvc 流程。dispatcherServlet（实现 servlet）接收请求 -->  根据 url 查找对应 handler --> HandlerMapping 响应执行链（Interceptor + Handler(Controller)） --> 请求 Handler（controller） --> controller 执行 --> 响应 ModelAndView --> ViewResolver 视图解析(将数据填充到 jsp、freemarker...) --> 响应 https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/framework/spring/SpringInterviewQuestions.md#62-springmvc-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E4%BA%86%E8%A7%A3%E5%90%97
- spring 事务管理。基于 aop 实现的事务管理机制，事务传播级别是为了解决多事务嵌套调用时，嵌套事务是否与外围事务共用相同事务回滚时一起回滚还是新建事务独立回滚的问题。默认 Required 级别，共用同一个事务。

### dubbo
### 集群容错
对应 ClusterInvoker 抽象，调用 provider 失败后不同的容错策略
- Failover。默认容错策略，失败自动切换
- Failfast。失败后抛异常
- Failsafe。失败打日志，响应空结果
- Failback。失败后响应空结果，异步重试
- Forking。并行调用多 provider，把结果塞进阻塞队列，有结果就响应
- Broadcast。遍历调用所有 provider

### 负载均衡
对应 LoadBalance 抽象，一般被集群容错 Cluster Invoker 调用
- 加权随机
- 加权轮询
- 最少活跃数
- 一致性 hash
  - 构建 TreeMap<hashCode,Invoker>(默认长度 160) 作为 hash 环，每个 invoker 根据 address 生成四个 hash 码，让 invoker 均匀分布在 map 里。每次 select 的时候根据参数值（可配参考哪几个参数）生成 hash 值，再从 treeMap 里找大于等于该值的 invoker 作为选中的 invoker。每次 invoker 列表更新时重新构建 hash 环

#### 服务导出
1. 在 spring 容器加载时 spring 会调用 dubbo 的解析实现，把 ServiceBean 注入到 ioc 容器
    - 实现 NamespaceHandler，用于解析整个 xml 文件
    - 实现各类 BeanDefinitionParser，用于解析单个 bean（application、service...）
2. ServiceBean 实现 ApplicationListener，感知到 ioc 容器加载完毕，开始服务导出
3. 前置处理
    - 配置检查。service 中 interface 合法等
    - 多注册中心支持。解析 registry 配置，转换成 URL
    - 根据配置组装 provider 对应的 URL。例:{protocol}://{ip}:{port}/{interfaceName}?methods={method1},{method2}&intereface={interfaceName}&pid=&...
4. 服务导出
    - 动态代理生成代理 Invoker(默认使用 javassist)
    - 暴露服务
        - 根据 URL 生成 Exporter。Protocol 保存了 key（group、interfaceName、version、） -> exporter 的 map
        - 启动服务器。开启 socket 监听，添加 channelHandler（解码器等，最后一个 inBound handler 处理为根据 key 找到对应的 exporter 持有的  invoker，调用 invoker 执行业务逻辑）
5. 服务注册。使用 zk 注册中心即创建对应的临时节点

#### 服务引用
1. ReferenceBean 实现 spring 的 FactoryBean，在实际使用到 reference 时调用 getObject()，开始服务引用过程
2. 配置处理。interfaceClass、methodConfig 等
3. 引用服务
  - 创建 Invoker。存在注册中心时，初始化对应服务字典（存储 provider 实例列表），向注册中心注册 consumer 信息，监听对应 provider 信息（动态更新服务字典，刷新 provider 列表时会走服务路由逻辑）。根据服务字典创建 Cluster Invoker，实现集群容错（failover、failfast、failsafe...）
  - 连接 provider。默认与 provider 节点建立单一长连接，添加 channelHandler(编码器、心跳等)，保存了 ip:port(单一 provider) --> ExchangeClient 的 map，实现使用单一长连接
4. 创建代理对象，响应代理对象

#### 服务调用
1. 调用服务引用中响应的代理对象中的 InvocationHandler 中的 invoke，调用 invoker，带上方法名、参数
2. 服务引用响应 invoker 为 cluster invoker，invoke 方法带集群容错处理，实际调用是走负载均衡，调用失败走不通的集群容错处理
3. cluster invoker 选择并调用的 invoker 为 DubboInvoker(默认 dubbo 协议)，invoke 方法获取 ExchangeClient 发送请求，响应 future
  - 同步调用直接返回 future.get()，一直阻塞到收到 provider 响应。Future 中存了 requestId -> future 的映射
4. 经编码序列化 走 netty channel.wirte() 最终发送请求信息（dubbo 数据包 header 带 requestId，body 带方法名、参数）
5. provider 接收到请求，把请求交给 dispatcher 处理
  - dispatcher 策略区别在于区不区分请求、响应、其他 netty 时间（连接、断开），把这些消息的处理直接在 io 线程处理还是扔给线程池。默认都给线程池
6. 调用后续的解码器，经 channel handler 传递调用到服务导出时带的 handler，reply 方法根据请求信息里带的 group、interfaceName、version 找到对应的 exporter，最终调用服务导出时的代理对象执行业务逻辑
7. 最终调用 netty channel.wirte()，把 provider 响应传给 consumer，响应中带 requestId
8. consumer 接收到 provider 的响应，经反序列化、解码后，调用 Future 接口，根据 requestId 找到 future 实例，设置 future 的 result，唤醒对应的 consumer 线程，之前阻塞在 get 上，唤醒后相应 result

### redis
#### 数据类型
- string
- hash
- list
- set
- sortedSet/zset
- bitmap
- hyperloglogs
    - 快速统计不同元素数量。例:pfadd key a b b c d,pfcount key = 4，可以用来统计 uv
- geospatial
    - 存地理位置
    
#### 过期策略
- 定期删除。默认 100ms 随机抽取设置了过期时间的 key，过期了删除
- 惰性删除。对该 key 有操作的时候检查是否过期
- 内存淘汰机制。上述两种方式可能少删 key，内存不够时使用淘汰机制。随机、最近未使用...等策略

#### 部署方式
- 单机模式
- 主从模式。一个 master 节点，多个 slave 节点，master 节点写，slave 节点读，主从备份。存在单点问题，master 挂了只能等 master 重启。
- 哨兵模式。在主从模式基础上加了哨兵集群，监控各个节点状态，master 挂的时候哨兵负责选举新的 master。所有节点都会存所有数据。
- 集群模式。哨兵模式的基础上，将数据分散到所有节点，默认 16384 个 slot，分布在不同节点，所有节点都存了哪些 slot 在那个节点，所有节点保持通信

#### 持久化方式
##### RDB 文件
类似 mysql sql 文件，记录数据。时效性较低，生成升本较大，数据恢复快，文件较小。
- 生成文件命令：save、bgsave。save 阻塞 redis 服务进程，生成期间不执行其他客户端命令。bgsave 派生子进程，由子进程来生成 rdb 文件，不阻塞其他命令

##### AOF文件
类似 mysql binlog，记录操作命令。时效性较强，生成成本较低，数据恢复较慢，文件大小较大。时效性强，当开启 aof 持久化时，redis 启动时优先使用 aof 还原数据
- aof 文件重写。记录命令使 aof 文件大小膨胀，实际会有多条无效命令，重写机制保证 aof 文件大小不会过大
    - redis 主进程派生子进程，子进程继承当前主进程所有数据，子进程异步生成新 aof 文件。派生后生成 aof 缓冲区，在子进程生成 aof 文件过程中将命令写入 aof 缓冲区
    - 子进程读取本进程中 redis 数据库当前数据，生成对应 aof（而不是解析 aof 文件）。且多进程之间也避免了线程安全问题
    - 子进程生成完毕后向父进程（redis 服务进程）发送信号。父进程阻塞同步的将 aof 缓冲区中内容写入新的 aof 文件，此时不会处理新的命令。缓冲区内容追加后，用新的 aof 文件覆盖旧的 aof 文件

#### 常见问题
- 缓存雪崩。缓存服务器崩溃/同一时间大量 key 过期，导致大量请求打到 db
  - key 过期时间添加随机值
  - 走 db 限流，配置降级策略
- 缓存穿透。故意请求不存在的值，导致大量无效 db 请求
  - 基本无效校验，id 为负直接响应空
  - 缓存无效值
- 缓存击穿。热点 key 失效的时候，大量并发请求打到 db
  - 情况允许，热点数据永不过期
  - 利用锁让少量请求走 db 更新缓存逻辑(更新逻辑简单不耗时)
  - 定时线程在过期前后台更新缓存值（更新逻辑较复杂较耗时）

#### 使用场景
- 使用 list 实现简单消息队列
- 使用 zset 实现简单延迟队列，以到期时间戳为 score
    - 消费者需要调用 zrangebyscore 获取最近任务时间戳，比较到期后 zrem 删除。多个命令非原子操作，多实例存在并发问题，使用 lua 脚本解决
- 使用 bitmap 实现布隆过滤器
    - bit 数组。用几个不同的 hash 算法算出一个 value 的 hash 值，把对应位设为 1。判断一个 value 是否存在时根据多个 hash 值对应的位是否都为 1，可以判断 value 一定不存在/可能存在。可以用来解决缓存穿透问题

### mongo
- 类 json 文件存储，可以不固定格式
- 使用内存映射机制，避免磁盘 io，查询效率高
- 基于 B 树可建立索引
- 天然支持分片，伸缩性强，集群自动故障转移


### zk
#### 脑裂问题
原master可能因为网络超时问题，zk内部心跳机制判定master宕机。其他slave重新选举了一个master，在通知所有zk客户端master重新选举前，原master恢复。导致部分zk客户端连接老master，部分客户端连接新master
- 解决方案？
    1. 超过半数选举通过才能成为master
    2. 每次选举递增epoch
    3. 原leader后续请求因为epoch不是最新，请求会被其他zk节点拒绝

### kafka
- pull 消费优化
  - 消费消息（broker 从磁盘中把消息传给 consumer）零拷贝
  - (6.1 协议设计)pull 中 fetchRequest 添加 session，两端都保存了拉取的 topic，不用每次都传，减少带宽使用
- 保证 producer 发消息幂等（不重消息）
  - producer 及 broker 维护了 <producer-id,partition-id> 对应的单调递增序列号，每条消息带序列号，broker 丢弃序列号小的消息避免重复消息，丢弃大的避免消息乱序。仅保证单 pid、partiionId 维度发消息幂等
- 为何不读写分离
  - 仅 leader 读写没有数据不一致、数据同步延迟问题
  - 通过将 leader 分布在不同 broker 实现一定程度的负载均衡
- 如何提高可靠性(尽量保证消息不丢)
  - producer 同步发消息，异步批量发消息机器宕机会丢消息
  - producer ack 设置成 -1，发送消息 leader、isr 落磁盘才成功。将 min.insync.replicas(isr 中最少副本数)设置为 >1，确保 isr 中一定存在 follower，isr 无 follower 时消息发送失败。unclean.leader.election.enable（是否允许选举非 isr 副本）设置为 false，避免选举非 isr 中副本
  - 多副本机制
  - consumer 端执行完业务逻辑后 commit
- kafka 高性能原因
  - 日志文件仅追加，顺序写磁盘，很好利用操作系统页缓存，操作系统级别缓存服务重启缓存依旧有效，不归 jvm 管理，也不会 full gc
  - 消费者消费消息时如果页缓存存在，直接使用零拷贝
  - producer 批量且异步（分主线程、sender 线程）发送消息，对应的消息格式也做了一定优化（不会每条消息带 topic、partition，消息格式上分组），日志编码使用变长字段，缩短字节数，且可以压缩
- 增加 topic 性能下降原因
    - 一个 partition 对应一个日志文件，单 partition 为顺序 io，当 topic 数目增加，单个 broker 机器上分到的 partition 数目增多，可能退化成随机 io

#### 为什么用 kafka
##### 功能性
- 天然支持点对点、消费订阅模式
- 支持消息回溯，一些业务补偿比较方便
- 消息使用磁盘堆积持久化，容量更大，顺序存储吞吐量也不低
##### 性能
- 高吞吐量
  
### netty
#### 为何高性能
- 基于 nio 异步非阻塞，reactor 单线程处理 io 事件，减少 cpu 上下文切换
- 可使用直接内存做到零拷贝
- 内存池化设计，循环利用 ByteBuf 避免频繁创建销毁性能消耗

#### 一般流程
- 引导 server 端，创建 ServerBootstrap 设置服务端参数
  - 设置 EventLoopGroup（boss、worker）
  - 设置 channel 类型（nio-NioServerSocketChannel/bio）
  - 设置 ChannelInitializer 组装 ChannelPipeline，定义 ChannelHandler 数据处理逻辑顺序
  - 设置端口号
- 引导 client 端，创建 Bootstrap 设置客户端参数
  - 设置 EventLoop
  - 设置 channel 类型（nio-NioSocketChannel/bio）
  - 设置 ChannelInitializer 组装 ChannelPipeline，定义 ChannelHandler 数据处理逻辑顺序
  - 设置 server address

#### reactor 线程（EventLoop）
- 轮询IO事件。不断地调用 jdk selector 的 select（eventLoop 持有 selector），轮询过程中不断检查是否有到期的定时任务跟普通任务，有任务就让出
- 处理轮询到的事件。boss reactor 轮询到连接事件，通过 pipeline （初始化后注册了一个 ServerBootstrapAcceptor）将连接扔给一个 worker reactor 线程处理。worker reactor 线程 channel 轮询到 read 事件，通过 pipeline 走 channelHandler 逻辑
- 执行任务队列中的任务。EventLoop 本身也是个 Executor，会接受各种 task，包括一些异步耗时任务在非 reactor 线程执行完后调用的 channel 操作（调用 context.fireChannelRead，若不在 reactor 线程，会被包成 task 放进任务队列）或者用户自定义的一些 task。内部维护 Queue 放 task(NioEventLoop 为 mpsc 多生产者，单消费者的 queue) 

#### 服务端启动
- 设置启动类参数。channel 类型，boss、worker EventLoop 数..
- 通过反射 new 对应类型的 channel。创建 channel、channelConfig、unsafe、pipeline（默认加了 head、tail handler，head 负责调用 Unsafe 做具体的操作，tail 处理未处理的异常、对未处理的消息告警）
- 初始化 server channel。设置 options、attrs，设置 worker channel 的 options、attrs，在 pipeline 中添加了 ServerBootstrapAcceptor handler
- 把 server channel 注册到 boss EventLoop 
- 调用 jdk channel bind，做真正端口绑定，开启监听

#### 新连接接入
- boos EventLoop reactor 线程 select 检测到 accept 事件，调用 channel 中 unsafe.read()
- unsafe read 到新的 channel，用 netty channel 封装了 jdk channel，交给 pipeline 处理，调到 ServerBootstrapAcceptor read()
- ServerBootstrapAcceptor read()。选择 worker EventLoop 中的一个，把新的 channel（关注 read 事件）注册到 eventLoop
    - 把 channel 注册到 selector 上，生成 selectKey
    - 触发 handlerAdded 调用 initChannel，执行用户自定义添加 channelHandler 逻辑
    - 设置该 selectKey 对 read 事件感兴趣
    
#### channelHandler 中耗时操作处理
将耗时操作放在业务线程/线程池中执行，而非 reactor 线程，执行完业务逻辑调用 channel 操作，将会被封装成 task 放进 eventLoop 的任务队列，reactor 线程轮训时处理对应的 channel 操作。
- 直接在 channelHandler 里使用业务线程池处理
- 将 channelHandler 添加到 pipeline 时指定该 channelHandler 执行使用的 EventExecutorGroup 

#### jdk nio
https://mp.weixin.qq.com/s/Qi7KXx17IdBr2nmlS0Gb2w
##### 一般流程
- 开启 ServerSocketChannel，绑定端口号，创建 Selector，并把 ServerSocketChannel accept 事件注册到 selector 上
- 死循环阻塞在 selector.select() 上（对应 netty 的 eventLoop reactor 线程），遍历 SelectionKey 处理对应的事件
- accept 事件则调用 ServerSocketChannel.accept 获取到 SocketChannel，建立起 server 与 client 的连接，并把 SocketChannel readable 事件注册到 selector 上
- readable 事件则创建 ByteBuffer，把 SocketChannel read 到的字节加载到 ByteBuffer 里，做解码及业务处理

##### netty 较 jdk nio 的抽象及优化
- jdk 需要手动编写轮询、注册 nio 事件（accept、readable）、线程派发逻辑，基本算模板代码。netty 通过抽象 EventLoop、ChannelFuture 将整体处理化为响应式事件驱动模型
- jdk 需要手动组织业务逻辑流转（解码、业务处理）。netty 通过抽象 ChannelPipeline、ChannelHandler 将业务逻辑处理跟网络层解耦
- jdk ByteBuffer 不能同时读写，读写切换时需要调用 flip 比较麻烦。netty 通过基于读写双指针实现的 ButeBuf 支持同时读写
- netty 内置常用协议编解码器(http、https、websocket..)，方便复用
- 解决了 jdk nio 的 selector 空轮询 bug，通过对 select 空轮询计数统计超过设置阈值从新创建 selector




## 数据结构
### 基础结构
- 跳表。通过不断建立索引提高查询效率，索引、索引的索引...
    - 为什么 redis 使用跳表而不用平衡查找树?
    - 跳表查询效率 ok，跳表的调整简单，随机判断新增节点是否升级为索引，维持平衡成本低。就是快，但需要更多存储

### 树
- 二叉查找树。左节点小于父节点，右节点大于父节点，二分查找。极端情况下树不平衡退化成链表。平衡二叉查找树为平衡大量旋转操作
- 2-3 树，也是平衡查找树，一个节点保存 1/2 个数据项，可以有 0-3 个子节点。算是在查询效率与变更效率间的折中把
- 红黑树。类似 2-3 树，红色节点旋上去其实就是个 2-3 树
- 堆。左右节点都小于父节点成为大根堆
- B树。多路平衡查找树，每个节点包含k个子节点，k 阶 B 树
    - 数据库索引为什么不用平衡查找树？无法一次性加载整个树，每次访问子节点如果在不同页就可能需要 io 操作，避免多次 io，不使用“瘦高”的平衡查找树，用“矮胖”的B树，相比内存中的遍历比较，io 更耗时
#### B+ 树
https://mp.weixin.qq.com/s?__biz=MzIxMjE5MTE1Nw==&mid=2653191027&idx=1&sn=4ba22e3ec8bd149f69fc0aba72e4347e&chksm=8c9909a9bbee80bfa1d8497ff0525df130414c1731b5aa5287bf16ea1cf86c8d8e6f20782184&scene=21#wechat_redirect

结构
- 父节点元素出现在子节点中，是子节点最大元素。根节点最大元素是整棵树最大元素，叶子节点包含全量信息
- 所有叶子节点单向指针相连
- 仅叶子节点带所有数据（数据行所有信息）

优点
- 仅叶子节点带数据，中间节点不带数据，相同页比 B 树加载节点更多，减少 io
- 必需到叶子才能拿到数据，查询效率更稳定
- 叶子节点带指针，范围查找更快

缺点
- 不同叶子节点物理上不连续，范围查找会产生随机 io(磁盘寻道)

### 图
https://mp.weixin.qq.com/s?__biz=MzIxMjE5MTE1Nw==&mid=2653197523&idx=1&sn=4edecca7392534177eef521511ff740b&chksm=8c99e609bbee6f1fdb736f1bc45da5f6b6765ce190db68eac5a65ca22cc2694dc151f8db828f&scene=21#wechat_redirect
- dfs 算法，使用递归实现
- bfs 算法，使用队列实现


## 算法
### 排序
#### 快排
每次获取一个列表中的基准元素，把小于基准的放到左边，大于基准的放到右边，再一直递归直到列表长度为1。 https://mp.weixin.qq.com/s?__biz=MzIxMjE5MTE1Nw==&mid=2653195042&idx=1&sn=2b0915cd2298be9f2163cc90a3d464da&chksm=8c99f9f8bbee70eef627d0f5e5b80a604221abb3a1b5617b397fa178582dcb063c9fb6f904b3&scene=21#wechat_redirect
- 如何选取基准元素？一般选第一个，所以如果列表本身逆序，效率退化成 n 的平方
- 如何把小于的放左边，大于的放右边？左右刷交换

#### 堆排序
将数组当做二叉树处理，调整为大根堆，循环删除堆顶元素。
https://mp.weixin.qq.com/s?__biz=MzIxMjE5MTE1Nw==&mid=2653195207&idx=2&sn=12689c6c1a92e7ec3cce4d423019ec2a&chksm=8c99f91dbbee700b8e760d06b27582037ab0713295dacf2b5a7a7f954c0032fe860aa0bf8b74&scene=21#wechat_redirect
- 数组怎么当做二叉树？idx 节点左子节点为 2✖idx+1，右子节点为 2✖idx+2
- 怎么调整？插入时新节点放在最后，一直上浮。删除时把最后的节点放到堆顶，一直下沉


## DDD
中台、DDD、微服务 https://www.infoq.cn/article/7QgXyp4Jh3-5Pk6LydWw
### DDD 与微服务关系
领域驱动设计主要关注：业务领域，划分领域边界；构建通用语言，高效沟通；对业务进行抽象，建立领域模型；维持业务和代码的逻辑一致性。

微服务主要关注：运行时进程间通信，能够容错和故障隔离；去中心化管理数据和去中心化治理；服务可以独立的开发、测试、构建和部署，按业务组织全功能团队；高内聚低耦合，职责单一。
DDD 是微服务的最佳设计方法

### DDD 实战
- https://www.infoq.cn/article/s_LFUlU6ZQODd030RbH9
- https://yq.aliyun.com/articles/716908
- https://yq.aliyun.com/articles/719251
#### 实现点
- 抽象数据存储层。不直接依赖 orm 框架的 mapper 及与数据表一致的 do
    - 抽象 repository 层。不直接依赖具体的 mapper 方便后续 orm 框架替换，repository 仅关注 do 与业务含义 entity 转换
    - 抽象具有业务含义及功能的 entity
        - 避免直接依赖 do，数据表字段变更无需大量变更
        - entity 纯内存对象，业务功能更容易测试
- 依赖其他系统的部分应该建立防腐层 Anti-Corruption Layer。不直接依赖特定外部系统而依赖防腐层
    - 适配作用。外部系统响应的数据不符合本系统的业务，需要做一定转换，避免重复的胶水代码
    - 统一缓存逻辑
    - 统一兜底/降级逻辑
    - 易于测试。可替换 stub
    - 方便后续切换实现
- 抽象中间件。不直接依赖具体的中间件实现，方便后续替换
- 封装业务逻辑
    - Entity 封装单对象状态行为及校验逻辑
    - Domain Primitive 封装与 entity 无关的计算逻辑
    - Domain Service 封装多对象逻辑

## ServiceMesh
微服务架构下，一个微服务中依赖了很多中间件 client（rpc、mq...），业务逻辑与基础组件在一个进程内。基础组件也需要不断迭代，会有升级困难跟版本兼容问题。serviceMesh 将业务逻辑服务与基础组件逻辑（proxy）拆成单机内的两个进程。服务间通信由 proxy 负责，业务逻辑与 proxy 通信。使得基础组件的 proxy 可以独立发布及升级，与业务逻辑解耦


## 其他
- 服务调用 https://mp.weixin.qq.com/s/VmiYGjiciFugmmdrztV9Ng
